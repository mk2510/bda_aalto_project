---
title: "BDA - Assignment 9"
author: "Anonymous"
header-includes:
   - \usepackage{listings}
output: 
  pdf_document: 
    toc: yes
    toc_depth: 1
urlcolor: blue
---
```{r setup, include=FALSE}
# This chunk sets echo = TRUE as default, that is print all code.
# knitr::opts_chunk$set can be used to set other notebook generation options, too.
# include=FALSE inside curly brackets makes this block not be included in the pdf.
# install.packages("remotes")
# remotes::install_github("avehtari/BDA_course_Aalto",
#         subdir = "rpackage", upgrade="never")
# install.packages("aaltobda")
knitr::opts_chunk$set(echo = TRUE)
library(aaltobda)
library(rstan)
library(loo)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
```



# Mathematical Models

## Hierarchical

$$
\begin{aligned}
y_n & \sim Bernoulli(logit^{-1}(x \times \beta_n))\\
\mu_{j} & \sim Normal(0, 100) \\
\sigma_{j} & \sim U(0,\infty) \\
\beta_{i,j} & \sim Normal(\mu_j, \sigma_j) \\
\end{aligned}
$$

We will first try to build a standart stand alone model to see, how t works:
```{r}
standart_model <- "
functions {
  real[] logit_transform(real[] x, real k, real x0) {
    int N = size(x);
    real xtemp[N];
    for (i in 1:N){
      xtemp[i] = 1 / (1 + exp(-k * (x[i] - x0)));
    }
     return xtemp;
  }
}

data {
    int<lower=0> J;
    int<lower=0> N; // number of data points
    real x[N]; // observation year
    vector[N] y; // observation number of drowned
    real xpred;  // prediction year
    real sigma;
}

parameters { 
  real alpha;
  real beta;
  //real<lower=0> sigma; // changed from upper to lower
}

transformed parameters {
  real mu[N] = logit_transform(x,alpha, beta);
}

model {
  alpha ~ normal(0.717949915905815,0.0001);
  beta ~ normal(0.5, 0.0001);
  y ~ normal(mu, sigma); // add here a semicolon
}

generated quantities {
  real ypred;
  real t[1];
  t[1] = xpred;
  ypred = normal_rng(logit_transform(t,alpha, beta)[1], sigma);

}

"


seperated_model <- "
functions {
  real[] logit_transform(real[] x, real k, real x0) {
    int N = size(x);
    real xtemp[N];
    for (i in 1:N){
      xtemp[i] = 1 / (1 + exp(-k * (x[i] - x0)));
    }
     return xtemp;
  }
}

data {
    int<lower=0> J;
    int<lower=1> M;
    int<lower=0> N; // number of data points
    real x[M,N]; // observation year
    real y[M,N]; // observation number of drowned
    real xpred;  // prediction year
    vector[M] muAlpha;
    vector[M] muBeta;
    vector[M] sigmaAlpha;
    vector[M] sigmaBeta;
    real sigma;
}

parameters { 
  real alpha[M];
  real beta[M];
}

transformed parameters {
  real mu[M,N];
  for (i in 1:M){
    mu[i,] = logit_transform(x[i,],alpha[i], beta[i]);
  }
}

model {
  for (i in 1:M){
    alpha[i] ~ normal(muAlpha[i], sigmaAlpha[i]);
    beta[i] ~ normal(muBeta[i], sigmaBeta[i]);
  }
  for (i in 1:M){
    y[i,] ~ normal(mu[i,], sigma); // add here a semicolon
  }
}

generated quantities {
  real ypred[M];
  real t[1];
  t[1] = xpred;
  for (i in 1:M){
    ypred[i] = normal_rng(logit_transform(t,alpha[i], beta[i])[1], sigma);
  }

}

"
```


```{r}
# setwd("/Users/max/Documents/UniMac/Aalto/BDA/bda_aalto_project/data")
data1 <- read.csv("data/Finland_output.csv")
data2 <- read.csv("data/Germany_output.csv")
data3 <- read.csv("data/Japan_output.csv")
data4 <- read.csv("data/Hong Kong_output.csv")
data5 <- read.csv("data/Portugal_output.csv")
```

```{r, results='hide', error=FALSE}
# mualpha is the gradient of the data -> 
muAlpha <- c(tail(data1$Y, n=1) - data1$Y[1],tail(data2$Y, n=1) - data2$Y[1],tail(data3$Y, n=1) - data3$Y[1],tail(data4$Y, n=1) - data4$Y[1],tail(data5$Y, n=1) - data5$Y[1])

# mubeta is the middel of our data -> 0.5
muBeta <- c(0.5,0.5,0.5,0.5,0.5)
xData <- rbind(data1$X,data2$X,data3$X,data4$X,data5$X)
#dim(xData) <- c(5,222)

yData <-rbind(data1$Y,data2$Y,data3$Y,data4$Y,data5$Y)
#dim(yData) <- c(5,222)

sigmaAlpha <- c(0.01, 0.01, 0.01, 0.01, 0.01)
sigmaBeta <- c(0.01, 0.01, 0.01, 0.01, 0.01)
```

```{r, results='hide', error=FALSE}
hm <- rstan::stan_model(model_code = seperated_model)
stan_data <- list(
    J = 1,
    N = length(data1$Y),
    M = 5,
    y = yData,
    x = xData,
    xpred = 1.1,
    sigma = 0.01,
    muAlpha = muAlpha,
    muBeta = muBeta,
    sigmaAlpha = sigmaAlpha,
    sigmaBeta = sigmaBeta
  )
model_hirachical <- rstan::sampling(hm, data = stan_data, warmup=3000, iter=4000, chains=8)
fit_hm <- extract(model_hirachical, permuted = TRUE, inc_warmup = FALSE)
```
```{r}
### PLOTS

plot(fit_hm$ypred[,1])
plot(fit_hm$ypred[,2])
plot(fit_hm$ypred[,3])
plot(fit_hm$ypred[,4])
plot(fit_hm$ypred[,5])

```

```{r, results='hide', error=FALSE}
hierarchical_model = "
data {
  int<lower=1> D;
  int<lower=0> N;
  int<lower=1> L;
  int<lower=0,upper=1> y[N];
  int<lower=1,upper=L> ll[N];
  row_vector[D] x[N];
}
parameters {
  real mu[D];
  real<lower=0> sigma[D];
  vector[D] beta[L];
}
model {
  for (d in 1:D) {
    mu[d] ~ normal(0, 100);
    for (l in 1:L)
      beta[l,d] ~ normal(mu[d], sigma[d]);
  }
  for (n in 1:N)
    y[n] ~ bernoulli(inv_logit(x[n] * beta[ll[n]]));
}
"
```

```{r, results='hide', error=FALSE}
hm <- rstan::stan_model(model_code = standart_model)
stan_data <- list(
    J = 1,
    N = length(data$Y),
    y = data$Y,
    x = data$X,
    xpred = 1.1,
    sigma = 0.0001
  )
model_hirachical <- rstan::sampling(hm, data = stan_data, warmup=3000, iter=4000)
fit_hm <- extract(model_hirachical, permuted = TRUE)
```