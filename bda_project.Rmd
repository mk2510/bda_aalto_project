---
title: "BDA - Assignment 9"
author: "Anonymous"
header-includes:
   - \usepackage{listings}
output: 
  pdf_document: 
    toc: yes
    toc_depth: 1
urlcolor: blue
---
```{r setup, include=FALSE}
# This chunk sets echo = TRUE as default, that is print all code.
# knitr::opts_chunk$set can be used to set other notebook generation options, too.
# include=FALSE inside curly brackets makes this block not be included in the pdf.
install.packages("remotes")
remotes::install_github("avehtari/BDA_course_Aalto",
        subdir = "rpackage", upgrade="never")
install.packages("aaltobda")
knitr::opts_chunk$set(echo = TRUE)
library(aaltobda)
library(rstan)
library(loo)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
```



# Mathematical Models

## Hierarchical

$$
\begin{aligned}
y_n & \sim Bernoulli(logit^{-1}(x \times \beta_n))\\
\mu_{j} & \sim Normal(0, 100) \\
\sigma_{j} & \sim U(0,\infty) \\
\beta_{i,j} & \sim Normal(\mu_j, \sigma_j) \\
\end{aligned}
$$

We will first try to build a standart stand alone model to see, how t works:
```{r}
standart_model <- "
functions {
  real[] logit_transform(real[] x, real k, real x0) {
    int N = size(x);
    real xtemp[N];
    for (i in 1:N){
      xtemp[i] = 1 / (1 + exp(-k * (x[i] - x0)));
    }
     return xtemp;
  }
}

data {
    int<lower=0> J;
    int<lower=0> N; // number of data points
    real x[N]; // observation year
    vector[N] y; // observation number of drowned
    real xpred;  // prediction year
    real sigma;
}

parameters { 
  real alpha;
  real beta;
  //real<lower=0> sigma; // changed from upper to lower
}

transformed parameters {
  real mu[N] = logit_transform(x,alpha, beta);
}

model {
  alpha ~ normal(0.7476352194,0.0001);
  beta ~ normal(0.5, 0.0001);
  y ~ normal(mu, sigma); // add here a semicolon
}

generated quantities {
  real ypred;
  real t[1];
  t[1] = xpred;
  ypred = normal_rng(logit_transform(t,alpha, beta)[1], sigma);

}

"
```

```{r}
hirachical_model <- "
functions {
  real[] logit_transform(real[] x, real k, real x0) {
    int N = size(x);
    real xtemp[N];
    for (i in 1:N){
      xtemp[i] = 1 / (1 + exp(-k * (x[i] - x0)));
    }
     return xtemp;
  }
}

data {
    int<lower=0> J;
    int<lower=1> M;
    int<lower=0> N; // number of data points
    real x[M,N]; // observation year
    real y[M,N]; // observation number of drowned
    real xpred;  // prediction year
    real sigma;
    
}

parameters { 
  real alpha[M];
  real beta[M];
  vector[M] muAlpha;
  vector[M] muBeta;
  real[M] sigma
  real sigmaAlpha;
  real sigmaBeta
}

transformed parameters {
  real mu[M,N];
  for (i in 1:M){
    mu[i,] = logit_transform(x[i,],alpha[i], beta[i]);
  }
  
}

model {
  
  for (i in 1:M){
    muAlpha[i] ~ normal(0.5, 0.001);
    muBeta[i] ~ normal(0.5, 0.001);
  }
  for (i in 1:M){
        sigma[i] ~ inv_chi_sqrt(50);
  }
  sigmaAlpha ~ inv_chi_sqrt(60);
  sigmaBeta ~ inv_chi_sqrt(60);

  
    alpha ~ normal(muAlpha,0.0001);
    beta ~ normal(muBeta, 0.0001);

    
  for (i in 1:M){
    y[i,] ~ normal(mu[i,], sigma[i]); // add here a semicolon
    
  }
 
}

generated quantities {
  real ypred[M];
  real t[1];
  t[1] = xpred;
  for (i in 1:M){
    ypred[i] = normal_rng(logit_transform(t,alpha[i], beta[i])[1], sigma);
  }

}

"
```


```{r}
seperated_model <- "
functions {
  real[] logit_transform(real[] x, real k, real x0) {
    int N = size(x);
    real xtemp[N];
    for (i in 1:N){
      xtemp[i] = 1 / (1 + exp(-k * (x[i] - x0)));
    }
     return xtemp;
  }
}

data {
    int<lower=0> J;
    int<lower=1> M;
    int<lower=0> N; // number of data points
    real x[M,N]; // observation year
    real y[M,N]; // observation number of drowned
    real xpred;  // prediction year
}

parameters {
  real alpha[M];
  real beta[M];
  real<lower = 0> sigma;
}

transformed parameters {
  real mu[M,N];
  for (i in 1:M){
    mu[i,] = logit_transform(x[i,],alpha[i], beta[i]);
  }
}

model {
  for (i in 1:M){
    // as prior we will change it to the same values
    alpha[i] ~ inv_chi_square(10);
    //alpha[i] ~ normal(0,100);
    beta[i] ~ normal(0,1);
  }
  
  sigma ~ inv_chi_square(10);
  for (i in 1:M){
    y[i,] ~ normal(mu[i,], sigma); 
  }
}

generated quantities {
  real ypred[M];
  real t[1];
  t[1] = xpred;
  for (i in 1:M){
    ypred[i] = normal_rng(logit_transform(t,alpha[i], beta[i])[1], sigma);
  }

}

"
```



```{r}
# setwd("/Users/max/Documents/UniMac/Aalto/BDA/bda_aalto_project/data")
data1 <- read.csv("data/Finland_output.csv")
data2 <- read.csv("data/Germany_output.csv")
data3 <- read.csv("data/Portugal_output.csv")
data4 <- read.csv("data/Hong Kong_output.csv")
data5 <- read.csv("data/Japan_output.csv")
```

```{r}
plot(data5$Y)
```

```{r, results='hide', error=FALSE}
xData <- c(data1$X,data2$X,data3$X,data4$X,data5$X)
dim(xData) <- c(5,222)

yData <-c(data1$Y,data2$Y,data3$Y,data4$Y,data5$Y)
dim(yData) <- c(5,222)

hm <- rstan::stan_model(model_code = seperated_model)
stan_data <- list(
    J = 1,
    N = length(data1$Y),
    M = 5,
    y = yData,
    x = xData,
    xpred = 1.1
)
model_hirachical <- rstan::sampling(hm, data = stan_data, warmup=3000, iter=4000)
fit_hm <- extract(model_hirachical, permuted = TRUE, inc_warmup = FALSE)
plot(fit_hm$mu[4000,1,])
```