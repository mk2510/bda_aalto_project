---
title: "BDA - Assignment 9"
author: "Anonymous"
header-includes:
   - \usepackage{listings}
output: 
  pdf_document: 
    toc: yes
    toc_depth: 1
urlcolor: blue
bibliography: ["reference.bib"] 
---
```{r setup, include=FALSE}
# This chunk sets echo = TRUE as default, that is print all code.
# knitr::opts_chunk$set can be used to set other notebook generation options, too.
# include=FALSE inside curly brackets makes this block not be included in the pdf.
#install.packages("remotes")
#remotes::install_github("avehtari/BDA_course_Aalto",
#        subdir = "rpackage", upgrade="never")
#install.packages("aaltobda")
knitr::opts_chunk$set(echo = TRUE)
library(aaltobda)
library(rstan)
library(loo)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
```

# 1. Introduction

It's been almost 2 years since the covid-19 started in December 2019, and it's been 1 year since world vaccination has been started December 2020. Even though most of the countries rushing into vaccination and some countries are picking over 80% rate in vaccination, the pandemic seems unstoppable. One of the popular idea to stop the pandemic is that to achieve a 'herd-immunity threshold, which occurs when a large portion of a community (the herd) becomes immune to a disease, making the spread of disease from person to person unlikely. Immune individuals are unlikely to contribute to disease transmission, disrupting chains of infection, which stops or slows the spread of disease (wiki citation). 
It is known that the herd-immunity threshold is achievable only with high vaccination rates, and many scientists had thought that once people started being immunized en masse, herd immunity would permit society to return to normal. Most estimates had placed the threshold at 60â€“70% of the population gaining immunity, either through vaccinations or past exposure to the virus(nature citation).
Down below shows the graph of population fully vaccinated by countries.
```{r}
knitr::include_graphics("./image/share-people-fully-vaccinated-covid_world.png")
```

As the high vaccination rate is a big part of ending pandemic by achieving herd-immunity, our group was interested in predicting how much high vaccination rate that countries will achieve in future. As we expect the cumulative vaccination rate graph will follow logit function, we set our model as a logit function. We picked 5 countries,which are Finland, Portugal, Japan, Germany,and Hongkong for our data. The cumulative vaccination graphs in these countries roughly follow the logit function and our main modeling idea is to see find which model the data fits well (seperate model or hierarchical model) and to predict the future vaccination rate. 

Down below shows the barplot of population rate who received at least one dose of covid19 vaccine by countries in our interest.
```{r}
knitr::include_graphics("./image/share-people-vaccinated-covid.png")
```
Down below shows the barplot of population rate of fully vaccinated against covid19 by countries in our interest.
```{r}
knitr::include_graphics("./image/share-people-fully-vaccinated-covid_bar.png")
```
Down below shows the barplot of fully vaccinated population rate by countries in our interest.
```{r}
knitr::include_graphics("./image/share-people-fully-vaccinated-covid_plot.png")
```

# 2. Dataset

Datasets down below show cumulative covid vaccinations rate by countries( collected from [linked phrase](https://ourworldindata.org/covid-vaccinations)).Country  column shows the country of this data. X column is originally from the date when the country started vaccination to the recent date of vaccination. We normalized the date column by giving index 0 to number of date and deviding it with the number of date. As the time length of the vaccination differs by country, we uniformly picked the 222 datapoints from the datasets before normalize the X column. Y column shows the covid vaccination rate in the country. With the cumulative covid vaccination number, we devide it by 2 times population because most of the vaccines require 2 doses to be fully vaccinated. Therefore, dimension of all datasets are (222,3).

```{r}
setwd('/Users/chuhyeongyeong/2021_period1/bayesian_data_analysis/bda_aalto_project')
finland <- read.csv("data/Finland_output.csv")
germany <- read.csv("data/Germany_output.csv")
hongkong <- read.csv('data/Hong Kong_output.csv')
portugal <- read.csv('data/Portugal_output.csv')
japan <- read.csv('data/Japan_output.csv')
```

```{r}
cat('dimenstion of Finland dataset: ',dim(finland),'\n')
cat('dimenstion of Germany dataset: ',dim(germany),'\n')
cat('dimenstion of HongKong dataset: ',dim(hongkong),'\n')
cat('dimenstion of Portugal dataset: ',dim(portugal),'\n')
cat('dimenstion of Japan dataset: ',dim(japan),'\n')
```


```{r}
total= rbind(finland,germany,hongkong,portugal,japan)
ggplot(data = total, aes(x = X, y = Y, color = Country)) +
    geom_line() +
    ggtitle("Cumulative covid19 vaccination rate") +
    xlab("time") + ylab("vaccination rate")
```

# Mathematical Models

## Hierarchical

$$
\begin{aligned}
y_n & \sim Bernoulli(logit^{-1}(x \times \beta_n))\\
\mu_{j} & \sim Normal(0, 100) \\
\sigma_{j} & \sim U(0,\infty) \\
\beta_{i,j} & \sim Normal(\mu_j, \sigma_j) \\
\end{aligned}
$$

We will first try to build a standart stand alone model to see, how t works:
```{r}
standart_model <- "
functions {
  real[] logit_transform(real[] x, real k, real x0) {
    int N = size(x);
    real xtemp[N];
    for (i in 1:N){
      xtemp[i] = 1 / (1 + exp(-k * (x[i] - x0)));
    }
     return xtemp;
  }
}

data {
    int<lower=0> J;
    int<lower=0> N; // number of data points
    real x[N]; // observation year
    vector[N] y; // observation number of drowned
    real xpred;  // prediction year
    real sigma;
}

parameters { 
  real alpha;
  real beta;
  //real<lower=0> sigma; // changed from upper to lower
}

transformed parameters {
  real mu[N] = logit_transform(x,alpha, beta);
}

model {
  alpha ~ normal(0.7476352194,0.0001);
  beta ~ normal(0.5, 0.0001);
  y ~ normal(mu, sigma); // add here a semicolon
}

generated quantities {
  real ypred;
  real t[1];
  t[1] = xpred;
  ypred = normal_rng(logit_transform(t,alpha, beta)[1], sigma);

}

"
```

```{r}
hirachical_model <- "
functions {
  real[] logit_transform(real[] x, real k, real x0) {
    int N = size(x);
    real xtemp[N];
    for (i in 1:N){
      xtemp[i] = 1 / (1 + exp(-k * (x[i] - x0)));
    }
     return xtemp;
  }
}

data {
    int<lower=0> J;
    int<lower=1> M;
    int<lower=0> N; // number of data points
    real x[M,N]; // observation year
    real y[M,N]; // observation number of drowned
    real xpred;  // prediction year
    real sigma;
    
}

parameters { 
  real alpha[M];
  real beta[M];
  vector[M] muAlpha;
  vector[M] muBeta;
  real[M] sigma
  real sigmaAlpha;
  real sigmaBeta
}

transformed parameters {
  real mu[M,N];
  for (i in 1:M){
    mu[i,] = logit_transform(x[i,],alpha[i], beta[i]);
  }
  
}

model {
  
  for (i in 1:M){
    muAlpha[i] ~ normal(0.5, 0.001);
    muBeta[i] ~ normal(0.5, 0.001);
  }
  for (i in 1:M){
        sigma[i] ~ inv_chi_sqrt(50);
  }
  sigmaAlpha ~ inv_chi_sqrt(60);
  sigmaBeta ~ inv_chi_sqrt(60);

  
    alpha ~ normal(muAlpha,0.0001);
    beta ~ normal(muBeta, 0.0001);

    
  for (i in 1:M){
    y[i,] ~ normal(mu[i,], sigma[i]); // add here a semicolon
    
  }
 
}

generated quantities {
  real ypred[M];
  real t[1];
  t[1] = xpred;
  for (i in 1:M){
    ypred[i] = normal_rng(logit_transform(t,alpha[i], beta[i])[1], sigma);
  }

}

"
```


```{r}
seperated_model <- "
functions {
  real[] logit_transform(real[] x, real k, real x0) {
    int N = size(x);
    real xtemp[N];
    for (i in 1:N){
      xtemp[i] = 1 / (1 + exp(-k * (x[i] - x0)));
    }
     return xtemp;
  }
}

data {
    int<lower=0> J;
    int<lower=1> M;
    int<lower=0> N; // number of data points
    real x[M,N]; // observation year
    real y[M,N]; // observation number of drowned
    real xpred;  // prediction year
}

parameters {
  real alpha[M];
  real beta[M];
  real<lower = 0> sigma;
}

transformed parameters {
  real mu[M,N];
  for (i in 1:M){
    mu[i,] = logit_transform(x[i,],alpha[i], beta[i]);
  }
}

model {
  for (i in 1:M){
    // as prior we will change it to the same values
    alpha[i] ~ inv_chi_square(1);
    //alpha[i] ~ normal(0,100);
    beta[i] ~ normal(0.5,1);
  }
  
  sigma ~ inv_chi_square(1);
  for (i in 1:M){
    y[i,] ~ normal(mu[i,], sigma); 
  }
}

generated quantities {
  real ypred[M];
  real t[1];
  t[1] = xpred;
  for (i in 1:M){
    ypred[i] = normal_rng(logit_transform(t,alpha[i], beta[i])[1], sigma);
  }

}

"
```



```{r}
# setwd("/Users/max/Documents/UniMac/Aalto/BDA/bda_aalto_project/data")
data1 <- read.csv("data/Finland_output.csv")
data2 <- read.csv("data/Germany_output.csv")
data3 <- read.csv("data/Portugal_output.csv")
data4 <- read.csv("data/Hong Kong_output.csv")
data5 <- read.csv("data/Japan_output.csv")
```

```{r}
plot(data5$Y)
```

```{r, results='hide', error=FALSE}
xData <- rbind(data1$X,data2$X,data3$X,data4$X,data5$X)
#dim(xData) <- c(5,222)

yData <-rbind(data1$Y,data2$Y,data3$Y,data4$Y,data5$Y)
#dim(yData) <- c(5,222)

hm <- rstan::stan_model(model_code = seperated_model)
stan_data <- list(
    J = 1,
    N = length(data1$Y),
    M = 5,
    y = yData,
    x = xData,
    xpred = 1.1
)
model_hirachical <- rstan::sampling(hm, data = stan_data, warmup=3000, iter=4000)
fit_hm <- extract(model_hirachical, permuted = TRUE, inc_warmup = FALSE)
plot(fit_hm$mu[3000,1,])
```