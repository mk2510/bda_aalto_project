---
title: "BDA - Assignment 9"
author: "Anonymous"
header-includes:
   - \usepackage{listings}
output: 
  pdf_document: 
    toc: yes
    toc_depth: 1
urlcolor: blue
bibliography: ["reference.bib"] 
---
```{r setup, include=FALSE}
# This chunk sets echo = TRUE as default, that is print all code.
# knitr::opts_chunk$set can be used to set other notebook generation options, too.
# include=FALSE inside curly brackets makes this block not be included in the pdf.
#install.packages("remotes")
#remotes::install_github("avehtari/BDA_course_Aalto",
#        subdir = "rpackage", upgrade="never")
#install.packages("aaltobda")
knitr::opts_chunk$set(echo = TRUE)
library(aaltobda)
library(rstan)
library(loo)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
```

# 1. Introduction

It's been almost 2 years since the covid-19 started in December 2019, and it's been 1 year since world vaccination has been started December 2020. Even though most of the countries rushing into vaccination and some countries are picking over 80% rate in vaccination, the pandemic seems unstoppable. One of the popular idea to stop the pandemic is that to achieve a 'herd-immunity threshold, which occurs when a large portion of a community (the herd) becomes immune to a disease, making the spread of disease from person to person unlikely. Immune individuals are unlikely to contribute to disease transmission, disrupting chains of infection, which stops or slows the spread of disease (wiki citation). 
It is known that the herd-immunity threshold is achievable only with high vaccination rates, and many scientists had thought that once people started being immunized en masse, herd immunity would permit society to return to normal. Most estimates had placed the threshold at 60â€“70% of the population gaining immunity, either through vaccinations or past exposure to the virus(nature citation).
Down below shows the graph of population fully vaccinated by countries.
```{r}
knitr::include_graphics("./image/share-people-fully-vaccinated-covid_world.png")
```

As the high vaccination rate is a big part of ending pandemic by achieving herd-immunity, our group was interested in predicting how much high vaccination rate that countries will achieve in future. As we expect the cumulative vaccination rate graph will follow logit function, we set our model as a logit function. We picked 5 countries,which are Finland, Portugal, Japan, Germany,and Hongkong for our data. The cumulative vaccination graphs in these countries roughly follow the logit function and our main modeling idea is to see find which model the data fits well (seperate model or hierarchical model) and to predict the future vaccination rate. 

Down below shows the barplot of population rate who received at least one dose of covid19 vaccine by countries in our interest.
```{r}
knitr::include_graphics("./image/share-people-vaccinated-covid.png")
```
Down below shows the barplot of population rate of fully vaccinated against covid19 by countries in our interest.
```{r}
knitr::include_graphics("./image/share-people-fully-vaccinated-covid_bar.png")
```
Down below shows the barplot of fully vaccinated population rate by countries in our interest.
```{r}
knitr::include_graphics("./image/share-people-fully-vaccinated-covid_plot.png")
```

# 2. Dataset

Datasets down below show cumulative covid vaccinations rate by countries( collected from [linked phrase](https://ourworldindata.org/covid-vaccinations)).Country  column shows the country of this data. X column is originally from the date when the country started vaccination to the recent date of vaccination. We normalized the date column by giving index 0 to number of date and deviding it with the number of date. As the time length of the vaccination differs by country, we uniformly picked the 222 datapoints from the datasets before normalize the X column. Y column shows the covid vaccination rate in the country. With the cumulative covid vaccination number, we devide it by 2 times population because most of the vaccines require 2 doses to be fully vaccinated. Therefore, dimension of all datasets are (222,3).

```{r}
setwd('/Users/chuhyeongyeong/2021_period1/bayesian_data_analysis/bda_aalto_project')
finland <- read.csv("data/Finland_output.csv")
germany <- read.csv("data/Germany_output.csv")
hongkong <- read.csv('data/Hong Kong_output.csv')
portugal <- read.csv('data/Portugal_output.csv')
japan <- read.csv('data/Japan_output.csv')
```

```{r}
cat('dimenstion of Finland dataset: ',dim(finland),'\n')
cat('dimenstion of Germany dataset: ',dim(germany),'\n')
cat('dimenstion of HongKong dataset: ',dim(hongkong),'\n')
cat('dimenstion of Portugal dataset: ',dim(portugal),'\n')
cat('dimenstion of Japan dataset: ',dim(japan),'\n')
```


```{r}
total= rbind(finland,germany,hongkong,portugal,japan)
ggplot(data = total, aes(x = X, y = Y, color = Country)) +
    geom_line() +
    ggtitle("Cumulative covid19 vaccination rate") +
    xlab("time") + ylab("vaccination rate")
```

# Mathematical Models

## Seperated Model

$$
\begin{aligned}
y_{i j} \mid \alpha_i,\beta_i, \sigma &\sim \operatorname{Normal}\left(\operatorname{logit} (\alpha_i, \beta_i), \sigma\right) \\
\alpha_i &\sim \text{inv}\chi^2(1) \\
\beta_i &\sim N(0.5,1) \\
\sigma &\sim \text{inv}\chi^2(1)
\end{aligned}
$$

## Hirachical Model

$$
\begin{aligned}
y_{i j} \mid \alpha_i,\beta_i, \sigma &\sim \operatorname{Normal}\left(\operatorname{logit} (\alpha_i, \beta_i), \sigma\right) \\
\beta_{j}\mid \mu_0, \theta &\sim \operatorname{Normal}(\mu_0, \theta)\\
\alpha_{j} \mid \sigma_{0} & \sim \operatorname{Inv}-\chi^{2}\left(\sigma_{0}\right) \\
\sigma & \sim \operatorname{Inv}-\chi^{2}(1) \\
\theta & \sim \operatorname{Inv}-\chi^{2}(1) \\
\sigma_{0} & \sim \operatorname{Inv}-\chi^{2}(1) \\
\mu_{0} & \sim \operatorname{Normal}(0,1)
\end{aligned}
$$

We will first try to build the seperated model in stan


```{r}
seperated_model <- "
functions {
  real[] logit_transform(real[] x, real k, real x0) {
    int N = size(x);
    real xtemp[N];
    for (i in 1:N){
      xtemp[i] = 1 / (1 + exp(-k * (x[i] - x0)));
    }
     return xtemp;
  }
}

data {
    int<lower=0> J;
    int<lower=1> M;
    int<lower=0> N; // number of data points
    real x[M,N]; // observation year
    real y[M,N]; // observation number of drowned
    real xpred;  // prediction year
}

parameters {
  real alpha[M];
  real beta[M];
  real<lower = 0> sigma;
}

transformed parameters {
  real mu[M,N];
  for (i in 1:M){
    mu[i,] = logit_transform(x[i,],alpha[i], beta[i]);
  }
}

model {
  for (i in 1:M){
    // as prior we will change it to the same values
    alpha[i] ~ inv_chi_square(1);
    beta[i] ~ normal(0.5,1);
  }
  
  sigma ~ inv_chi_square(1);
  for (i in 1:M){
    y[i,] ~ normal(mu[i,], sigma); 
  }
}

generated quantities {
  real ypred[M];
  real t[1];
  t[1] = xpred;
  for (i in 1:M){
    ypred[i] = normal_rng(logit_transform(t,alpha[i], beta[i])[1], sigma);
  }

}

"
```

Now we will build the hirachical model in stan:
```{r}
hirachical_model <- "
functions {
  real[] logit_transform(real[] x, real k, real x0) {
    int N = size(x);
    real xtemp[N];
    for (i in 1:N){
      xtemp[i] = 1 / (1 + exp(-k * (x[i] - x0)));
    }
     return xtemp;
  }
}

data {
    int<lower=0> J;
    int<lower=1> M;
    int<lower=0> N; // number of data points
    real x[M,N]; // observation year
    real y[M,N]; // observation number of drowned
    real xpred;  // prediction year
}

parameters {
  real alpha[M];
  real beta[M];
  real<lower = 0> sigma;
  real<lower = 0> hyper_sigma;
  real hyper_mu;
  real<lower = 0> hyper_alpha;
}

transformed parameters {
  real mu[M,N];
  for (i in 1:M){
    mu[i,] = logit_transform(x[i,],alpha[i], beta[i]);
  }
}

model {
    hyper_mu ~ normal(0, 1);
    hyper_sigma ~ inv_chi_square(10);
    hyper_alpha ~ inv_chi_square(10);
    
  for (i in 1:M){
    // as prior we will change it to the same values
    alpha[i] ~ inv_chi_square(hyper_alpha);
    beta[i] ~ normal(hyper_mu,hyper_sigma);
  }
  
  sigma ~ inv_chi_square(1);
  for (i in 1:M){
    y[i,] ~ normal(mu[i,], sigma); 
  }
}

generated quantities {
  real ypred[M];
  real t[1];
  t[1] = xpred;
  for (i in 1:M){
    ypred[i] = normal_rng(logit_transform(t,alpha[i], beta[i])[1], sigma);
  }

}

"
```

# Prior selection

For both models we choose to use weakly informative priors. 

## Prior choice of the seperated model

For the seperated model, the $\alpha$ prior needed to fullfill two criteria. First it needed to be a positive number, as we can expect from the vaccination, that the rate is rising and not dropping. Also, as the vaccination should follow roughly a logit function, as it can be observed from the data, we can expect to have a gradient, which is more likely around $1$ than bigger than $50$. Hence the prior of $\operatorname{Inv}-\chi^{2}(1) $ was choosen.
 
For our $\beta$ prior estimation we know, that it should be in the range of $[0,1]$, as this is the range of our x-Data. Therefore we choose $N(0.5,1)$. 

The variance of our y-sampling should be a positive number. As we can also expect it to be quite small, as we want our model following the line quite tightly, we choose here as well $\operatorname{Inv}-\chi^{2}(1) $.

## Prior choices of the hirachical model

The hirachical model has the following priors. The $\alpha$- prior still has the same distribution function: $\operatorname{Inv}-\chi^{2}(\cdot) $, with the same reasoning as for the seperated model. Here however, the parameter for the function gets sampled as well. With the same reasoning about the order of magnitude of our parameter we choose $\operatorname{Inv}-\chi^{2}(1)$ as a suitable weakly informative prior. 
![inverse chi sqare](invchisqrt1.png)
As we can see here, the PDF of the probability distribution has nearly all amount of its mass in the interval of $[0,10]$

The $\beta$ prior is again, like in the seperated model a normal distribution $N(\cdot,\cdot)$. For the first argument, we choose a normal distribution of $N(0,1)$, with the reasoning, that we expect it to be located somewhere in the interval of $[0,1]$, as this is the range of the data. 
The prior of the variance is given by a $\operatorname{Inv}-\chi^{2}(1)$, as here as well we want to have a variance, which is not much larger, than our expected interval.

```{r}
# setwd("/Users/max/Documents/UniMac/Aalto/BDA/bda_aalto_project/data")
data1 <- read.csv("data/Finland_output.csv")
data2 <- read.csv("data/Germany_output.csv")
data3 <- read.csv("data/Portugal_output.csv")
data4 <- read.csv("data/Hong Kong_output.csv")
data5 <- read.csv("data/Japan_output.csv")
```

```{r}
plot(data5$Y)
```

```{r, results='hide', error=FALSE}
xData <- rbind(data1$X,data2$X,data3$X,data4$X,data5$X)
#dim(xData) <- c(5,222)

yData <-rbind(data1$Y,data2$Y,data3$Y,data4$Y,data5$Y)
#dim(yData) <- c(5,222)

sm <- rstan::stan_model(model_code = seperated_model)
stan_data <- list(
    J = 1,
    N = length(data1$Y),
    M = 5,
    y = yData,
    x = xData,
    xpred = 1.1
)
model_standart <- rstan::sampling(sm, data = stan_data, warmup=3000, iter=4000)
fit_hm <- extract(model_standart, permuted = TRUE, inc_warmup = FALSE)
plot(fit_hm$mu[3000,1,])
```

```{r}
hm <- rstan::stan_model(model_code = hirachical_model)
stan_data <- list(
    J = 1,
    N = length(data1$Y),
    M = 5,
    y = yData,
    x = xData,
    xpred = 1.1
)
model_hirachical <- rstan::sampling(hm, data = stan_data, warmup=3000, iter=4000)
fit_hm <- extract(model_hirachical, permuted = TRUE, inc_warmup = FALSE)
plot(fit_hm$mu[3000,1,])
```


# Rhat and ESS analysis
We will use the build in tool from the stan library to analyse the convergence of our chains. 
```{r}
sum_seperate <- summary(model_standart)
sum_hirachical <- summary(model_hirachical)
cat("Rhat of seperate model: \n")
sum_seperate$summary[1:11,10]
```