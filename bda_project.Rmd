---
title: "BDA - Assignment 9"
author: "Anonymous"
header-includes:
   - \usepackage{listings}
output: 
  pdf_document: 
    toc: yes
    toc_depth: 1
urlcolor: blue
---
```{r setup, include=FALSE}
# This chunk sets echo = TRUE as default, that is print all code.
# knitr::opts_chunk$set can be used to set other notebook generation options, too.
# include=FALSE inside curly brackets makes this block not be included in the pdf.
#install.packages("remotes")
#remotes::install_github("avehtari/BDA_course_Aalto",
#        subdir = "rpackage", upgrade="never")
#install.packages("aaltobda")
knitr::opts_chunk$set(echo = TRUE)
library(aaltobda)
library(rstan)
library(loo)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
```

# 1. Introduction
## Motivation
It's been almost 2 years since the covid-19 started in December 2019. World vaccination has been started December 2020 but 
## Problem
## Main modeling idea
## Showing some illustrative figure

# 2. Dataset

Datasets down below show cumulative covid vaccinations rate by countries( collected from [linked phrase](https://ourworldindata.org/covid-vaccinations)).Country  column shows the country of this data. X column is originally from the date when the country started vaccination to the recent date of vaccination. We normalized the date column by giving index 0 to number of date and deviding it with the number of date. As the time length of the vaccination differs by country, we uniformly picked the 222 datapoints from the datasets before normalize the X column. Y column shows the covid vaccination rate in the country. With the cumulative covid vaccination number, we devide it by 2 times population because most of the vaccines require 2 doses to be fully vaccinated. Therefore, dimension of all datasets are (222,3).

```{r}
setwd('/Users/chuhyeongyeong/2021_period1/bayesian_data_analysis/project/bda_aalto_project-master')
finland <- read.csv("data/Finland_output.csv")
germany <- read.csv("data/Germany_output.csv")
hongkong <- read.csv('data/HongKong_output.csv')
portugal <- read.csv('data/Portugal_output.csv')
japan <- read.csv('data/Japan_output.csv')
```

```{r}
cat('dimenstion of Finland dataset: ',dim(finland),'\n')
cat('dimenstion of Germany dataset: ',dim(germany),'\n')
cat('dimenstion of HongKong dataset: ',dim(hongkong),'\n')
cat('dimenstion of Portugal dataset: ',dim(portugal),'\n')
cat('dimenstion of Japan dataset: ',dim(japan),'\n')
```


```{r}
total= rbind(finland,germany,hongkong,portugal,japan)
ggplot(data = total, aes(x = X, y = Y, color = Country)) +
    geom_line() +
    ggtitle("Cumulative covid19 vaccination rate") +
    xlab("time") + ylab("vaccination rate")
```

# Mathematical Models

## Hierarchical

$$
\begin{aligned}
y_n & \sim Bernoulli(logit^{-1}(x \times \beta_n))\\
\mu_{j} & \sim Normal(0, 100) \\
\sigma_{j} & \sim U(0,\infty) \\
\beta_{i,j} & \sim Normal(\mu_j, \sigma_j) \\
\end{aligned}
$$

We will first try to build a standart stand alone model to see, how t works:
```{r}
standart_model <- "
functions {
  real[] logit_transform(real[] x, real k, real x0) {
    int N = size(x);
    real xtemp[N];
    for (i in 1:N){
      xtemp[i] = 1 / (1 + exp(-k * (x[i] - x0)));
    }
     return xtemp;
  }
}

data {
    int<lower=0> J;
    int<lower=0> N; // number of data points
    real x[N]; // observation year
    vector[N] y; // observation number of drowned
    real xpred;  // prediction year
    real sigma;
}

parameters { 
  real alpha;
  real beta;
  //real<lower=0> sigma; // changed from upper to lower
}

transformed parameters {
  real mu[N] = logit_transform(x,alpha, beta);
}

model {
  alpha ~ normal(0.7476352194,0.0001);
  beta ~ normal(0.5, 0.0001);
  y ~ normal(mu, sigma); // add here a semicolon
}

generated quantities {
  real ypred;
  real t[1];
  t[1] = xpred;
  ypred = normal_rng(logit_transform(t,alpha, beta)[1], sigma);

}

"
```

```{r}
seperated_model <- "
functions {
  real[] logit_transform(real[] x, real k, real x0) {
    int N = size(x);
    real xtemp[N];
    for (i in 1:N){
      xtemp[i] = 1 / (1 + exp(-k * (x[i] - x0)));
    }
     return xtemp;
  }
}

data {
    int<lower=0> J;
    int<lower=1> M;
    int<lower=0> N; // number of data points
    real x[M,N]; // observation year
    real y[M,N]; // observation number of drowned
    real xpred;  // prediction year
}

parameters {
  real alpha[M];
  real beta[M];
  real<lower = 0> sigma;
}

transformed parameters {
  real mu[M,N];
  for (i in 1:M){
    mu[i,] = logit_transform(x[i,],alpha[i], beta[i]);
  }
}

model {
  for (i in 1:M){
    // as prior we will change it to the same values
    alpha[i] ~ inv_chi_square(1);
    //alpha[i] ~ normal(0,100);
    beta[i] ~ normal(0.5,1);
  }
  
  sigma ~ inv_chi_square(1);
  for (i in 1:M){
    y[i,] ~ normal(mu[i,], sigma); 
  }
}

generated quantities {
  real ypred[M];
  real t[1];
  t[1] = xpred;
  for (i in 1:M){
    ypred[i] = normal_rng(logit_transform(t,alpha[i], beta[i])[1], sigma);
  }

}

"
```


```{r}
hirachical_model <- "
functions {
  real[] logit_transform(real[] x, real k, real x0) {
    int N = size(x);
    real xtemp[N];
    for (i in 1:N){
      xtemp[i] = 1 / (1 + exp(-k * (x[i] - x0)));
    }
     return xtemp;
  }
}

data {
    int<lower=0> J;
    int<lower=1> M;
    int<lower=0> N; // number of data points
    real x[M,N]; // observation year
    real y[M,N]; // observation number of drowned
    real xpred;  // prediction year
}

parameters {
  real alpha[M];
  real beta[M];
  real<lower = 0> sigma;
  real<lower = 0> hyper_sigma;
  real hyper_mu;
  real<lower = 0> hyper_alpha;
}

transformed parameters {
  real mu[M,N];
  for (i in 1:M){
    mu[i,] = logit_transform(x[i,],alpha[i], beta[i]);
  }
}

model {
    hyper_mu ~ normal(0, 1);
    hyper_sigma ~ inv_chi_square(10);
    hyper_alpha ~ gamma(2,0.6);
    
  for (i in 1:M){
    // as prior we will change it to the same values
    alpha[i] ~ inv_chi_square(1);
    beta[i] ~ normal(hyper_mu,hyper_sigma);
  }
  
  sigma ~ inv_chi_square(1);
  for (i in 1:M){
    y[i,] ~ normal(mu[i,], sigma); 
  }
}

generated quantities {
  real ypred[M];
  real t[1];
  t[1] = xpred;
  for (i in 1:M){
    ypred[i] = normal_rng(logit_transform(t,alpha[i], beta[i])[1], sigma);
  }

}

"
```



```{r}
# setwd("/Users/max/Documents/UniMac/Aalto/BDA/bda_aalto_project/data")
data1 <- read.csv("data/Finland_output.csv")
data2 <- read.csv("data/Germany_output.csv")
data3 <- read.csv("data/Portugal_output.csv")
data4 <- read.csv("data/Hong Kong_output.csv")
data5 <- read.csv("data/Japan_output.csv")
```

```{r}
plot(data5$Y)
```

```{r, results='hide', error=FALSE}
xData <- rbind(data1$X,data2$X,data3$X,data4$X,data5$X)
#dim(xData) <- c(5,222)

yData <-rbind(data1$Y,data2$Y,data3$Y,data4$Y,data5$Y)
#dim(yData) <- c(5,222)

hm <- rstan::stan_model(model_code = hirachical_model)
stan_data <- list(
    J = 1,
    N = length(data1$Y),
    M = 5,
    y = yData,
    x = xData,
    xpred = 1.1
)
model_hirachical <- rstan::sampling(hm, data = stan_data, warmup=3000, iter=4000)
fit_hm <- extract(model_hirachical, permuted = TRUE, inc_warmup = FALSE)
plot(fit_hm$mu[3000,1,])
```